{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babb9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.signal import butter, filtfilt, iirnotch, sosfiltfilt, cheb2ord, cheby2, firwin, find_peaks\n",
    "from sklearn.decomposition import FastICA\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "from scipy import interpolate\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.signal import welch\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import HTML\n",
    "from pyclustering.cluster.gmeans import gmeans\n",
    "from pyclustering.cluster.xmeans import xmeans\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.utils.metric import type_metric, distance_metric\n",
    "from sklearn.svm import SVC\n",
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections.abc import Mapping\n",
    "from typing import List, Sequence, Any, Optional\n",
    "import hdbscan\n",
    "import warnings\n",
    "np.warnings = warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d9af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64938f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_virtual_emg(emg_data, virtual_bipolars):\n",
    "  # --- データ読み込み ---\n",
    "  emg_data = emg_data\n",
    "\n",
    "  # === スライディングウィンドウ抽出 ===\n",
    "  n_samples = emg_data.shape[0]\n",
    "  segments = []\n",
    "  time_stamps = []\n",
    "\n",
    "  # 座標グリッド\n",
    "  x = np.arange(8)\n",
    "  y = np.arange(8)\n",
    "  xv, yv = np.meshgrid(x, y)\n",
    "  coords = np.vstack((xv.ravel(), yv.ravel()))\n",
    "  # # パラメータ計算\n",
    "  # f = RectBivariateSpline(x, y, map_2d)\n",
    "\n",
    "  virtual_emg = []\n",
    "  for i in range(n_samples):\n",
    "    f = RectBivariateSpline(x, y, emg_data[i].reshape(8,8))\n",
    "    z_list = []\n",
    "    for bipolar in virtual_bipolars:\n",
    "      x1=bipolar[0]\n",
    "      y1=bipolar[1]\n",
    "      x2=bipolar[2]\n",
    "      y2=bipolar[3]\n",
    "      z1 = f(x1, y1)\n",
    "      z2 = f(x2, y2)\n",
    "      z_diff = z1 - z2\n",
    "      z_list.append(z_diff)\n",
    "    virtual_emg.append(np.array(z_list).reshape(-1))\n",
    "  virtual_emg = np.array(virtual_emg)\n",
    "\n",
    "  # print(emg_data.shape)\n",
    "  # print(virtual_emg.shape)\n",
    "\n",
    "  return virtual_emg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e608d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(virtual_emg, labels, fs=2000, window_ms=50, stride_ms=20):\n",
    "  # --- データ読み込み例（ここではダミーデータ） ---\n",
    "  fs = fs  # サンプリング周波数\n",
    "  window_ms = window_ms    # ウィンドウ幅 [ms]\n",
    "  stride_ms = stride_ms    # スライド幅 [ms]\n",
    "  window_size = int(fs * (window_ms / 1000))  # サンプル数に変換\n",
    "  stride_size = int(fs * stride_ms / 1000)  # スライド数\n",
    "  n_samples = virtual_emg.shape[0]\n",
    "  X = []\n",
    "  y = []\n",
    "  for start in range(0, n_samples - window_size + 1, stride_size):\n",
    "      end = start + window_size\n",
    "      window_emg = virtual_emg[start:end, :]\n",
    "      #特徴量抽出\n",
    "      rms = rms(window_emg) # shape: (virtual_bipolar_channels,)\n",
    "      X.append(rms)\n",
    "      y.append(labels)\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58aa8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#分類器\n",
    "def SVC_classifier(X_session1, y_session1, X_session2, y_session2):\n",
    "\n",
    "    X_train = np.array(X_session1).reshape(-1,1)\n",
    "    y_train = np.array(y_session1).reshape(-1,1)\n",
    "    X_test = np.array(X_session2).reshape(-1,1)\n",
    "    y_test = np.array(y_session2).reshape(-1,1)\n",
    "\n",
    "    # データ分割\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # SVMモデル学習\n",
    "    model = SVC(kernel='rbf', probability=True, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    prob_matrix = model.predict_proba(X_test) # shape: (n_test_samples, n_train_classes)\n",
    "    # === 各テストラベルごとに学習クラスへの平均確率を出力 ===\n",
    "    class_labels = model.classes_  # 学習クラス（例: [0, 1, 2]）\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for test_label in np.unique(y_test):\n",
    "        idx = y_test.reshape(-1) == test_label\n",
    "        mean_prob = np.mean(prob_matrix[idx], axis=0)  # 学習クラスへの平均確率\n",
    "        result.append([test_label] + list(mean_prob))\n",
    "\n",
    "    # # === 表形式で表示 ===\n",
    "    # columns = ['Test Label'] + [f\"P(Train={cls})\" for cls in class_labels]\n",
    "    # df_result = pd.DataFrame(result, columns=columns)\n",
    "    # print(df_result)\n",
    "    \n",
    "    return result, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ba6844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff(train_idx, test_idx, center_direction_session1, center_direction_session2):\n",
    "    center_direction_session1 = center_direction_session1\n",
    "    center_direction_session2 = center_direction_session2\n",
    "    #計算\n",
    "    center_x_train = np.array(center_direction_session1)[train_idx, 0]\n",
    "    center_y_train = np.array(center_direction_session1)[train_idx, 1]\n",
    "    theta_train = np.array(center_direction_session1)[train_idx, 2]\n",
    "    center_x_test = np.array(center_direction_session2)[test_idx, 0]\n",
    "    center_y_test = np.array(center_direction_session2)[test_idx, 1]\n",
    "    theta_test = np.array(center_direction_session2)[test_idx, 2]\n",
    "    center_x_diff = center_x_train - center_x_test\n",
    "    center_y_diff = center_y_train - center_y_test\n",
    "    theta_diff = theta_train - theta_test\n",
    "    return center_x_diff, center_y_diff, theta_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8534841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_analyzer(result, y_train, y_test, center_direction_session1, center_direction_session2):\n",
    "  max_train_idx = []\n",
    "  for i in range(np.array(result).shape[0]):\n",
    "    j = np.argmax(np.array(result)[i,1:])\n",
    "    max_train_idx.append(j)\n",
    "  # print(max_train_idx)\n",
    "  diff =[]\n",
    "  for k in set(max_train_idx):\n",
    "    if max_train_idx.count(k) >=2:\n",
    "      idx = max_train_idx == k\n",
    "      l = np.argmax(np.array(result)[idx, k+1], axis=0)\n",
    "      max_test_idx = [i for i, j in enumerate(idx) if j == True]\n",
    "      # print(f'result[{max_test_idx[l]},{k+1}], train:{np.unique(y_train)[k]}, test:{np.unique(y_test)[max_test_idx[l]]}')\n",
    "      center_x_diff, center_y_diff, theta_diff = calc_diff(k, max_test_idx[l], center_direction_session1, center_direction_session2)\n",
    "      # print(f'x_diff={center_x_diff}, y_diff={center_y_diff}, theta_diff={theta_diff}')\n",
    "      diff.append({\"train\": np.unique(y_train)[k], \"test\": np.unique(y_test)[max_test_idx[l]], \"x_diff\": center_x_diff, \"y_diff\": center_y_diff, \"theta_diff\": theta_diff})\n",
    "    else:\n",
    "      # print(f'result[{max_train_idx.index(k)},{k+1}], train:{np.unique(y_train)[k]}, test:{np.unique(y_test)[max_train_idx.index(k)]}')\n",
    "      center_x_diff, center_y_diff, theta_diff = calc_diff(k, max_train_idx.index(k), center_direction_session1, center_direction_session2)\n",
    "      # print(f'x_diff={center_x_diff}, y_diff={center_y_diff}, theta_diff={theta_diff}')\n",
    "      diff.append({\"train\": np.unique(y_train)[k], \"test\": np.unique(y_test)[max_train_idx.index(k)], \"x_diff\": center_x_diff, \"y_diff\": center_y_diff, \"theta_diff\": theta_diff})\n",
    "\n",
    "  return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa40dd81",
   "metadata": {},
   "source": [
    "# 分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c8e28",
   "metadata": {},
   "source": [
    "## データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39a18c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subject    x_mean     x_std    y_mean     y_std  theta_mean  theta_std\n",
      "0        1  0.568279  0.532239  0.585948  0.480677   11.574118  11.151453\n"
     ]
    }
   ],
   "source": [
    "# CSV を DataFrame に読み込み\n",
    "df_loaded = pd.read_csv(\"output/test3_ptp_gaussianfitting_abs_sessions.csv\", encoding=\"utf-8-sig\")\n",
    "\n",
    "print(df_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3061cd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>x_mean</th>\n",
       "      <th>x_std</th>\n",
       "      <th>y_mean</th>\n",
       "      <th>y_std</th>\n",
       "      <th>theta_mean</th>\n",
       "      <th>theta_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.568279</td>\n",
       "      <td>0.532239</td>\n",
       "      <td>0.585948</td>\n",
       "      <td>0.480677</td>\n",
       "      <td>11.574118</td>\n",
       "      <td>11.151453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject    x_mean     x_std    y_mean     y_std  theta_mean  theta_std\n",
       "0        1  0.568279  0.532239  0.585948  0.480677   11.574118  11.151453"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
